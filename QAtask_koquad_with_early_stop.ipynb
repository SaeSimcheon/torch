{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apEnhGiY7z9r"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "import math\n",
        "import gc\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "KSlnVOLE9Omm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained('klue/roberta-base')\n",
        "data=load_dataset('squad_kor_v1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "fb95f3db3173433ca5439bc2ad2dd0d8",
            "7e13b668fd5244fca031dfe958e85e34",
            "e31003ef5c1d445ea4581c140c60a70d",
            "516ecb4422284d0dad649c5200a762d2",
            "73480de1a4c1425e98b735fb3e7352ab",
            "246b8dc291eb48c2b9c0d56c1c2a8628",
            "41136791513949e6aad6f38bf755681e",
            "4ba8e50b5d304d559ddc4a0b02effebd",
            "8783bfdc199e41b89cf6d3d285e1af57",
            "72160dc51ccf4a189424be3ec87064e8",
            "1ac16bb78f4e493b8b37e319d38006ac",
            "9c8d686220684ee7b871805afbb3aff6",
            "8db53ce4c20e4a31a973a8eccf93e162",
            "5b0ba5a211ae4ef3a98b62a2b1704aad",
            "6d3284be0b0b478ba7c0623bcfceac54",
            "62c781253f93473e8300a04e97e6a99a",
            "c3fe7ccf0f2042ce8c442f043cbe7c0c",
            "f5b002d8b7f14e83a213eb17c41fc082",
            "23d7f834202c475482ca0953c1159697",
            "e942fe5875bc4910a15c7a844b71d6f5",
            "7299fb5cebd34c3ebb35137a90a0ccdf",
            "efaa71186ce24f2ea7c8438feb90f086",
            "dc8670d14b9f427ba9ffd183fd0e1bcf",
            "ef60855d3f8848e69b944283f9dd983e",
            "9ba4b224285f47d8a98b194e2532c4e3",
            "d7c3a004699a47b7916b8305175b2b3d",
            "194da1c6dc184616b9f5dfd772310195",
            "d1e98131dadc460e9673e33fb2523de1",
            "812cc3a82010422d8ae45f69fab1a6c3",
            "c89b55f0d4c1447398991d6c75d961a4",
            "2bc724f35dc3473eb654834fe1bdf929",
            "3c81b19b9a124e9183ee9db204d4ad55",
            "917afad3e7a547d281d3032cac675cb7",
            "f7871c5c3eb444d8a23bb3442273a900"
          ]
        },
        "id": "wcUJhpJo9WsL",
        "outputId": "70ce5991-d1d0-4bd2-e16b-043fb3e4c24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/11.6M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb95f3db3173433ca5439bc2ad2dd0d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e13b668fd5244fca031dfe958e85e34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/60407 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8db53ce4c20e4a31a973a8eccf93e162"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/5774 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef60855d3f8848e69b944283f9dd983e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "  batch_size = 8\n",
        "  hidden_dim = 512\n",
        "  num_heads = 8\n",
        "  num_layers = 4\n",
        "  head_dim = hidden_dim // num_heads\n",
        "  ffn_dim = hidden_dim * 4\n",
        "  max_length = 256\n",
        "  dropout_rate = 0.1\n",
        "  is_training = True\n",
        "  voca_size = tokenizer.vocab_size\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "oBSm8VhIHLwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QAdataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,config,data,tokenizer):\n",
        "    self.data = data\n",
        "    self.tokenizer = tokenizer\n",
        "    self.config = config\n",
        "    self.sequence = []\n",
        "    self._build()\n",
        "  def _build(self):\n",
        "    question = self.data['question']\n",
        "    context = self.data['context']\n",
        "    answers = self.data['answers']\n",
        "\n",
        "    for i in range(len(self.data)):\n",
        "      q = question[i]\n",
        "      c = context[i]\n",
        "      answer = answers[i]\n",
        "      answer_text = answer['text'][0]\n",
        "      answer_start = answer['answer_start'][0]\n",
        "      answer_end = answer_start + len(answer_text)\n",
        "\n",
        "      tokenized = tokenizer(q,c,return_attention_mask=True,return_offsets_mapping=True,return_token_type_ids=True,padding = 'max_length',max_length = self.config.max_length,truncation = True)\n",
        "\n",
        "      input_ids = tokenized['input_ids']\n",
        "      attention_mask = tokenized['attention_mask']\n",
        "      offset_mapping = tokenized['offset_mapping']\n",
        "\n",
        "      context_index = -1\n",
        "\n",
        "      for index,val in enumerate(tokenized.sequence_ids()):\n",
        "        if index > 0 and val == 1 :\n",
        "          context_index = index\n",
        "          break\n",
        "\n",
        "      start = -1\n",
        "      end = -1\n",
        "\n",
        "      for index in range(self.config.max_length):\n",
        "\n",
        "        if context_index > index :\n",
        "          continue\n",
        "        start_offset,end_offset = offset_mapping[index]\n",
        "        if start_offset <= answer_start < end_offset and start == -1:\n",
        "          start = index\n",
        "\n",
        "        if start_offset <= answer_end-1 < end_offset :\n",
        "          end = index\n",
        "      if start == -1 or end == -1 :\n",
        "        continue\n",
        "      sequence = {\n",
        "          'input_ids':input_ids,\n",
        "          'attention_mask':attention_mask,\n",
        "          'offset_mapping' : offset_mapping,\n",
        "          'c':c,\n",
        "          'answer_text':answer_text\n",
        "          }\n",
        "      if self.config.is_training :\n",
        "        sequence['start'] = start\n",
        "        sequence['end'] = end\n",
        "\n",
        "      self.sequence.append(sequence)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.sequence)\n",
        "  def __getitem__(self,i):\n",
        "    sample = self.sequence[i]\n",
        "\n",
        "    output ={\n",
        "        'input_ids' : torch.tensor(sample['input_ids'],dtype = torch.long),\n",
        "        'attention_mask' : torch.tensor(sample['attention_mask'],dtype = torch.long),\n",
        "        'offset_mapping' : torch.tensor(sample['offset_mapping'],dtype = torch.long),\n",
        "        'c' : sample['c'],\n",
        "        'answer_text' : sample['answer_text']\n",
        "    }\n",
        "    if self.config.is_training :\n",
        "      output['start'] = torch.tensor(sample['start'],dtype = torch.long)\n",
        "      output['end'] = torch.tensor(sample['end'],dtype = torch.long)\n",
        "    return output"
      ],
      "metadata": {
        "id": "dlY5W5r-AWJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qadata=QAdataset(config,data['train'],tokenizer)"
      ],
      "metadata": {
        "id": "0fmg00zvgUij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_qadata=QAdataset(config,data['validation'],tokenizer)"
      ],
      "metadata": {
        "id": "sboKR0eyG596"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load=torch.utils.data.DataLoader(qadata,batch_size = config.batch_size,drop_last = True)"
      ],
      "metadata": {
        "id": "lQwm97QEhIZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_load=torch.utils.data.DataLoader(val_qadata,batch_size = config.batch_size,drop_last = True)"
      ],
      "metadata": {
        "id": "gaD3aUvPHc50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "    self.linearQ = torch.nn.Linear(config.hidden_dim,config.hidden_dim)\n",
        "    self.linearK = torch.nn.Linear(config.hidden_dim,config.hidden_dim)\n",
        "    self.linearV = torch.nn.Linear(config.hidden_dim,config.hidden_dim)\n",
        "    self.linearO = torch.nn.Linear(config.hidden_dim,config.hidden_dim)\n",
        "  def forward(self,query,key,value,attention_mask):\n",
        "    B,S,H = query.shape\n",
        "    T = key.size(1)\n",
        "    N = self.config.num_heads\n",
        "    HD = self.config.head_dim\n",
        "\n",
        "    Q = self.linearQ(query).view(B,S,N,HD).transpose(2,1)\n",
        "    K = self.linearK(key).view(B,T,N,HD).transpose(2,1)\n",
        "    V = self.linearV(value).view(B,T,N,HD).transpose(2,1)\n",
        "\n",
        "    qk = torch.matmul(Q,K.transpose(3,2)) / math.sqrt(HD)\n",
        "\n",
        "    if attention_mask is not None :\n",
        "      # key masking\n",
        "      mask = torch.zeros_like(attention_mask,dtype = torch.float,device = self.config.device)\n",
        "      mask.masked_fill_(attention_mask.logical_not(),float('-inf'))\n",
        "      qk += mask.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    causal = torch.full((S,T),float('-inf'),dtype = torch.float,device= self.config.device).triu(diagonal = 1)\n",
        "\n",
        "    qk += causal.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    alpha = torch.softmax(qk, dim = -1)\n",
        "\n",
        "    scores = torch.matmul(alpha,V).transpose(2,1).contiguous().view(B,T,H)\n",
        "\n",
        "    out = self.linearO(scores)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "urv71lAwhIku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer(torch.nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "    self.mha_norm = torch.nn.LayerNorm(config.hidden_dim)\n",
        "    self.mha = MultiHeadAttention(config)\n",
        "    self.mha_dropout = torch.nn.Dropout(config.dropout_rate)\n",
        "\n",
        "    self.ffn = torch.nn.Sequential(\n",
        "        torch.nn.LayerNorm(config.hidden_dim),\n",
        "        torch.nn.Linear(config.hidden_dim,config.ffn_dim),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(config.ffn_dim,config.hidden_dim),\n",
        "        torch.nn.Dropout(config.dropout_rate)\n",
        "    )\n",
        "  def forward(self,src,attention_mask):\n",
        "    x = src\n",
        "\n",
        "    v = self.mha_norm(x)\n",
        "    x = x + self.mha_dropout(self.mha(v,v,v,attention_mask))\n",
        "    x = x + self.ffn(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "UusNapF17uIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask_test = torch.cat([torch.ones((16,256)),torch.zeros((16,256))],dim = -1)"
      ],
      "metadata": {
        "id": "23ejLCI17ueT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(torch.nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "    self.layers = torch.nn.ModuleList([Layer(config) for _ in range(config.num_layers)])\n",
        "\n",
        "  def forward(self,src,attention_mask):\n",
        "    x = src\n",
        "\n",
        "    for layer in self.layers :\n",
        "      x = layer(x,attention_mask)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "YzPLRpwYK0Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(torch.nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "    self.token_embedding = torch.nn.Embedding(config.voca_size,config.hidden_dim)\n",
        "    self.pos_embedding = torch.nn.Embedding(config.max_length,config.hidden_dim)\n",
        "    self.block = Block(config)\n",
        "    self.out_layer_norm = torch.nn.LayerNorm(config.hidden_dim)\n",
        "    self.start_out = torch.nn.Linear(config.hidden_dim,1)\n",
        "    self.end_out = torch.nn.Linear(config.hidden_dim,1)\n",
        "\n",
        "  def forward(self,src,attention_mask):\n",
        "    S = src.size(1)\n",
        "    tk_emb = self.token_embedding(src)\n",
        "    seq = torch.arange(S,dtype = torch.long,device = self.config.device)\n",
        "    pos_emb = self.pos_embedding(seq)\n",
        "    emb = tk_emb + pos_emb.unsqueeze(0)\n",
        "\n",
        "    out = self.block(emb,attention_mask)\n",
        "    out = self.out_layer_norm(out)\n",
        "\n",
        "    start = self.start_out(out).unsqueeze(-1)\n",
        "    end = self.end_out(out).unsqueeze(-1)\n",
        "    return start,end\n"
      ],
      "metadata": {
        "id": "Sex5DQcBMZ83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel,AutoConfig"
      ],
      "metadata": {
        "id": "8ETbFLpJkeck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_config=AutoConfig.from_pretrained('klue/roberta-base')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b33530d57e734db2a64dad5294f5943b",
            "a77e772e99d545d9b8756486e4c58ed2",
            "d78138b539a24ecd9240ebf213aa00ab",
            "90492b86cb82432a942e11a147d93ab7",
            "94b93c837b5f429889d5b595d33a1386",
            "5f00f9920ad848a48aa7370cbd4ffdf9",
            "9ddb585f24c848569f1ccc7dab171f7b",
            "78fa2add3c9a48d580b2b6cc4d1f62fc",
            "ad60385285944504b01348c655797b8d",
            "73e602cf1f32476cbead169f94854ac9",
            "924552f8573049bdb6d66877216bf22f"
          ]
        },
        "id": "EEKDB5t0wpPj",
        "outputId": "c0fe6fa3-8b9e-4992-f370-7f84aff02e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b33530d57e734db2a64dad5294f5943b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(torch.nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "    self.pre_trained = AutoModel.from_pretrained('klue/roberta-base')\n",
        "    self.out_layer_norm = torch.nn.LayerNorm(bert_config.hidden_size)\n",
        "    self.start_out = torch.nn.Linear(bert_config.hidden_size,1)\n",
        "    self.end_out = torch.nn.Linear(bert_config.hidden_size,1)\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    out = self.pre_trained(**inputs).last_hidden_state\n",
        "    out = self.out_layer_norm(out)\n",
        "\n",
        "    start = self.start_out(out).squeeze(-1)\n",
        "    end = self.end_out(out).squeeze(-1)\n",
        "    return start,end"
      ],
      "metadata": {
        "id": "zKBgDDDzm2RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del tr"
      ],
      "metadata": {
        "id": "uz4WoqV3uJPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "mn0EO3F3un1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr = Transformer(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6SB9GFipJTY",
        "outputId": "e8215b6f-691f-4f31-cd02-27fbb675f853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr.to(config.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WbapB7Zrw8S",
        "outputId": "7dc011b2-d750-4d03-ceef-b69ea6d58903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (pre_trained): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (out_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (start_out): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (end_out): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5"
      ],
      "metadata": {
        "id": "bJNA9r9VocfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_loss = torch.nn.CrossEntropyLoss()\n",
        "end_loss = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "mSaDhgGOpB_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminative Learning Rates / Layer-wise LR Decay도 적용해볼 수 있으나, 여기에서는 2e-5로 일률적으로 적용"
      ],
      "metadata": {
        "id": "OUxfbucbXokA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(tr.parameters(),lr = 2e-5)"
      ],
      "metadata": {
        "id": "THErNzAdpiYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []"
      ],
      "metadata": {
        "id": "4-1U-ixGp688"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_losses = []"
      ],
      "metadata": {
        "id": "_Ew7kHPWIVp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "BxUjyD26QrZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStop :\n",
        "  def __init__(self,method='max',delta = 0):\n",
        "    self.best_score = None\n",
        "    self.path = './qabest.pt'\n",
        "    self.patience = 3\n",
        "    self.method = method\n",
        "    self.no_impr = 0\n",
        "    self.stop = False\n",
        "    self.delta = delta\n",
        "\n",
        "\n",
        "  def __call__(self,model,val_metric):\n",
        "\n",
        "    score = -val_metric if self.method == 'min' else val_metric\n",
        "\n",
        "    if self.best_score is None :\n",
        "      self.best_score = score\n",
        "      self.checkpoint(model)\n",
        "    elif score <= self.best_score + self.delta :\n",
        "      self.no_impr +=1\n",
        "\n",
        "      if self.no_impr >= self.patience :\n",
        "        self.stop = True\n",
        "\n",
        "    else:\n",
        "      self.best_score = score\n",
        "      self.checkpoint(model)\n",
        "      self.no_impr = 0\n",
        "\n",
        "  def checkpoint(self,model):\n",
        "    torch.save(model.state_dict(),self.path)"
      ],
      "metadata": {
        "id": "T3AfF0EFiYNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ealrystop = EarlyStop('min',0)"
      ],
      "metadata": {
        "id": "sfxaENKYlp72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0\n",
        "  tr.train()\n",
        "  for b in tqdm(load,desc=f\"Training Epoch {epoch+1}\") :\n",
        "    opt.zero_grad()\n",
        "    inputs = {'input_ids':b['input_ids'].to(config.device),'attention_mask':b['attention_mask'].to(config.device)}\n",
        "    start_true,end_true=b['start'].to(config.device),b['end'].to(config.device)\n",
        "    start_pred,end_pred=tr(inputs)\n",
        "\n",
        "    start_cal = start_loss(start_pred,start_true)\n",
        "    end_cal = end_loss(end_pred,end_true)\n",
        "\n",
        "    loss = start_cal + end_cal\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    epoch_loss += loss.item()\n",
        "  epoch_loss /= len(load)\n",
        "  losses.append(epoch_loss)\n",
        "  print(f\"Epoch {epoch+1} Train Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "  epoch_loss = 0\n",
        "  tr.eval()\n",
        "  for b in tqdm(val_load, desc=f\"Validation Epoch {epoch+1}\") :\n",
        "    inputs = {'input_ids':b['input_ids'].to(config.device),'attention_mask':b['attention_mask'].to(config.device)}\n",
        "    start_true,end_true=b['start'].to(config.device),b['end'].to(config.device)\n",
        "\n",
        "    with torch.no_grad() :\n",
        "      start_pred,end_pred=tr(inputs)\n",
        "\n",
        "      start_cal = start_loss(start_pred,start_true)\n",
        "      end_cal = end_loss(end_pred,end_true)\n",
        "\n",
        "      loss = start_cal + end_cal\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "  epoch_loss /=len(val_load)\n",
        "  val_losses.append(epoch_loss)\n",
        "  print(f\"Epoch {epoch+1} Val Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "  ealrystop(tr,epoch_loss)\n",
        "\n",
        "  if ealrystop.stop :\n",
        "    break"
      ],
      "metadata": {
        "id": "N9crxA_bod5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418,
          "referenced_widgets": [
            "4f60e24e7fb34bb486a3ea189655c9f5",
            "d6056a9ff0954fdeb676c3d3f9fc926f",
            "af4cd3aff7414f7b873aa79860c03f8d",
            "e435724da00c4c1b8f781936428f4e34",
            "3280b901121d48cfa6239304e74ed3c0",
            "f0dcecbb2d9d4497b35a230c6d071173",
            "e4f23f8ceab444b39c91d81653c11efe",
            "1bd93e1422494525a2f1f1ebda3e9449",
            "5e6345fb338245a3906416eb53073a16",
            "d4b64c69dfab4f3d8eb130562cecd912",
            "85d7f34e43274c83bd7ffc015c0a41e5",
            "8bcd8c3e169a4aba87707e38cd79f808",
            "bab627cda0e64269b3cdc595bb2b4b9a",
            "8123f4597dce47b286f156f745713cdc",
            "f000cfdfc232488fac3f15eb57ccdf73",
            "06489254e5984aaba33415c9635f0452",
            "d1d78c4f62c544d3a8b4ed193628d581",
            "f3adc9bc3fc94c029337c4921ab2adaa",
            "b7bf59409162432f90863d1e0b0839b6",
            "4042279d61eb4ecc9e3bca72fe4f68c2",
            "2f8ad21ac4fb469fa772fc440abb88fa",
            "61f5f7c9d123420e81845613648644f6",
            "819bed41469446eebfed574c7691550b",
            "f05440b76af042d8b36354598d1ec27b",
            "9c51b99983464dde854c520db497b796",
            "c13e340118e644d38c397288fdb58441",
            "a2b2bad7ab9d4fdd9e61989234674477",
            "c8f4cd3c6e614a8e8058f1d5ce1cab96",
            "7d7149bff48a43d689874e69abe152e5",
            "c6d1c6b90f364298943b9dfab37f833d",
            "fcf1333b63cd49f6bfe0c8173c4e8254",
            "57d5231c3b404a3680511df441554c40",
            "92e7269527cf4b698043fe3b259b1c40",
            "91e182a0ba194eabb095c32d1ca2b8fb",
            "f8b1b549faa04240bd27497c968db63b",
            "497d32bf176d4a2c87c157a1515cde97",
            "c87c0beed086492eba03bd892f07cc1c",
            "325ed8bb1a41419cb8b4cfdbe4a86d7d",
            "77ad8297369b4fd68e884228d204b433",
            "99a8bcf4a1c04ad3aff458a73796a4f3",
            "cbd88c4b342c45f6ad9ccf8f888fdd4d",
            "d91d4757bed14799bdb37ba1109fa18f",
            "1c84d218a396418797d0df8db6f3043d",
            "1ca22b38db814c6f9dd37e71744ec5b2",
            "407918c8c7064dc3b9798c603ade82a0",
            "0f0d93ac237a4491852474acdaae224c",
            "7417f0950db94eb088057cba6184bea7",
            "4f710a0ef2194510855d739f6b11ddc8",
            "e8cc8d98450a4a8ca591adcf3a5f081d",
            "8d9282b3bbb24e6bb5d8c6c2347f74ff",
            "123eaf549a7440269ae7c00caf3d60c8",
            "b0f1ac505793456fa9adacd9936fa601",
            "cae1a9264e9b4b03b5afdeecae46dcea",
            "a01f5e45ddc44845b79edf6930e80be0",
            "5ecbf66198bf4c9d945605e0ca64734b",
            "eeae912b643c45668b3e657516056441",
            "1d57ff927f1e4923b82490b439ab9277",
            "503de5549d90402db3acb98ce8ab86e9",
            "83de0ee68c20440aac9b0300a4250d23",
            "b7d9b7eefda349308a5494cfd986be82",
            "1a19e56869e0473fb1e8c400fa4ea9a2",
            "6384ffe52cba4f1f87b2bee69f753122",
            "66fa9ece904e490b938d329288dce09b",
            "9fc19d43e2744b30bf3c400063f2252d",
            "2c02d71d9f164f5ba66c36c54417e814",
            "bfb03260d831425389b81ffa71a0f789",
            "9bc8c7568e69413cb19092f0d98235ad",
            "f0fafa994c38447f92264ef3333af430",
            "184257cc150143d5a6d856ea5d0dc8b3",
            "310c1a70e3b842699c36b3131ca32cf8",
            "29c132414fa44c03a9a1768b22f1e6ba",
            "dcfe52b5a4414f1593fb5dfa6c549ee1",
            "6ca3ebbca8fa4150bea4331dbf6790df",
            "b6c469fca42341e7aacb237cb295f290",
            "86135b275a99401c8649ea342d1b9718",
            "dcdf6c85a9cb4e3e8541f65b6e5bbb99",
            "b1c8d94351cd41ddb40188aea8a00e74",
            "2d55dc72417247c3b33023b9904aefb9",
            "fb5f2a091b574d94a9049a5d44dfa9f9",
            "edba43fceaac42a6b0d266080ca84067",
            "67e559894b3947b5b508c208ca52f36b",
            "24fd4ec1feb24ce1992a4fdf7b8e444e",
            "093255d83a5142bdad216cb842068746",
            "debfcbde7b744e73a057a6ab08332d15",
            "3017489967464514a36f9cf14b10ab12",
            "229a24fea677478ea3885756d6991925",
            "d47966e468cf48b584a2b2de3dac1de8",
            "a46ea3a24f0649e68bdd4d12a1927c4f"
          ]
        },
        "outputId": "27ad0655-7f87-48f5-dcb6-d989810f40d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training Epoch 1:   0%|          | 0/6820 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f60e24e7fb34bb486a3ea189655c9f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Train Loss: 1.0226\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation Epoch 1:   0%|          | 0/651 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bcd8c3e169a4aba87707e38cd79f808"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Val Loss: 0.7962\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training Epoch 2:   0%|          | 0/6820 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "819bed41469446eebfed574c7691550b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Train Loss: 0.5695\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation Epoch 2:   0%|          | 0/651 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91e182a0ba194eabb095c32d1ca2b8fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Val Loss: 0.8915\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training Epoch 3:   0%|          | 0/6820 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "407918c8c7064dc3b9798c603ade82a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Train Loss: 0.4049\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation Epoch 3:   0%|          | 0/651 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eeae912b643c45668b3e657516056441"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Val Loss: 0.9702\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training Epoch 4:   0%|          | 0/6820 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bc8c7568e69413cb19092f0d98235ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Train Loss: 0.3171\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation Epoch 4:   0%|          | 0/651 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d55dc72417247c3b33023b9904aefb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Val Loss: 1.0270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr-aRjcRWyYM",
        "outputId": "b7bb78dd-4634-48c0-ddeb-088b57ab86f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98k5C6wKXJNL",
        "outputId": "60da0e74-965d-4f32-b2bf-bd0e74be3b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 432200\n",
            "drwx------ 7 root root      4096 May 23 08:56 drive\n",
            "-rw-r--r-- 1 root root 442564039 May 23 06:44 qabest.pt\n",
            "drwxr-xr-x 1 root root      4096 May 14 13:38 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./qabest.pt /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "n1ynuTCiXKZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1epoch = about 41 min"
      ],
      "metadata": {
        "id": "TfL93bEEVkud"
      }
    }
  ]
}